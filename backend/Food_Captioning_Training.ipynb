{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a9061a-ef61-458e-8f11-da78d5941a2e",
   "metadata": {},
   "source": [
    "## 1. Tahap Preprocessing Data Teks (ingredients)\n",
    "\n",
    "Tahap ini krusial, teman-tman. Kolom `ingredients` kita masih berupa **string yang berisi list JSON** (misalnya `[\"chicken\",\"breading\",\"oil\"]`).\n",
    "\n",
    "**Goal-nya:** Kita harus membersihkan data itu dan mengubahnya jadi format yang siap dilatih model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f6501-f6be-4341-9fbf-76bae61df804",
   "metadata": {},
   "source": [
    "### A. Instalasi & Import Library\n",
    "\n",
    "**(Ini harus di-run pertama kali jika belum di-install di *environment* penelitian)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df822a05-7259-4e51-8cb9-3ee32d6feb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries jika belum ada\n",
    "# !pip install scikit-learn numpy tqdm -y\n",
    "# !pip install pillow -y \n",
    "\n",
    "# =======================================================\n",
    "# Library Wajib untuk Training & Preprocessing\n",
    "# =======================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast # Untuk mengonversi string list menjadi list Python\n",
    "\n",
    "# Sklearn untuk Multi-label Encoding\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Pillow untuk Image Processing (akan digunakan nanti)\n",
    "from PIL import Image\n",
    "\n",
    "# Tqdm untuk progress bar saat pemrosesan data\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f064386-447c-4fea-a6bb-bf77c0d15fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil dimuat. Total 100000 baris.\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas() \n",
    "\n",
    "# Definisikan path file CSV kamu\n",
    "file_path = 'dataset/MM-Food-100k.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Data berhasil dimuat. Total {len(df)} baris.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Gagal memuat data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81437cb-7c50-4dee-8144-4a49e0b7f8ff",
   "metadata": {},
   "source": [
    "### B. Cleaning dan Binarization (Label Encoding)\n",
    "\n",
    "Ini adalah **inti dari *preprocessing* label**.\n",
    "\n",
    "Kita akan mengonversi kolom `ingredients` menjadi **matriks biner** (nilai **0** dan **1**) yang merepresentasikan kehadiran setiap bahan unik dalam resep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35eb6f39-4222-43bc-b388-5479f95537d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hasil Encoding Ingredients ---\n",
      "Total bahan unik (output classes): 3577\n",
      "Shape Matriks Label (y): (100000, 3577)\n",
      "5 Bahan Unik Teratas: ['a2 milk' 'a5 wagyu beef' 'abalone' 'acai' 'accompaniments']\n"
     ]
    }
   ],
   "source": [
    "# 1. Konversi String List menjadi List Python\n",
    "# Kolom 'ingredients' adalah string, perlu diubah jadi list of string\n",
    "def convert_to_list(ingredients_str):\n",
    "    try:\n",
    "        # ast.literal_eval lebih aman daripada eval()\n",
    "        return ast.literal_eval(ingredients_str)\n",
    "    except:\n",
    "        # Jika ada error konversi, kembalikan list kosong\n",
    "        return []\n",
    "\n",
    "df['ingredients_list'] = df['ingredients'].apply(convert_to_list)\n",
    "\n",
    "# 2. Normalisasi Teks Ingredients (Opsional tapi Good Practice)\n",
    "# Menghilangkan spasi ekstra, membuat lowercase, dsb.\n",
    "def normalize_ingredients(ing_list):\n",
    "    return [ing.strip().lower() for ing in ing_list]\n",
    "\n",
    "df['ingredients_clean'] = df['ingredients_list'].apply(normalize_ingredients)\n",
    "\n",
    "# 3. Encoding Multi-Label\n",
    "# MultiLabelBinarizer akan menemukan semua bahan unik dan membuat kolom biner\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Latih encoder pada semua list bahan\n",
    "y_encoded = mlb.fit_transform(df['ingredients_clean'])\n",
    "\n",
    "# Buat DataFrame dari hasil encoding\n",
    "df_labels = pd.DataFrame(y_encoded, columns=mlb.classes_)\n",
    "\n",
    "# Gabungkan dengan DataFrame utama (opsional, tapi bagus untuk inspeksi)\n",
    "# df = pd.concat([df, df_labels], axis=1)\n",
    "\n",
    "print(\"\\n--- Hasil Encoding Ingredients ---\")\n",
    "print(f\"Total bahan unik (output classes): {len(mlb.classes_)}\")\n",
    "print(f\"Shape Matriks Label (y): {y_encoded.shape}\")\n",
    "\n",
    "# Tampilkan 5 bahan unik teratas\n",
    "print(f\"5 Bahan Unik Teratas: {mlb.classes_[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d00ff-2709-4ce5-8c7d-1232fe5eaaff",
   "metadata": {},
   "source": [
    "## 2. Tahap Preprocessing Gambar (Image Pipeline)\n",
    "\n",
    "Di sini, kita perlu merancang **Custom Dataset dan Data Generator** (menggunakan TensorFlow/Keras) untuk menangani *file* gambar dan juga melakukan **augmentasi** saat proses *training*.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c6563-0062-4c6a-8da3-cc656c2795c9",
   "metadata": {},
   "source": [
    "### A. Custom Generator (Image Data Augmentation & Resize)\n",
    "\n",
    "Karena kita pakai arsitektur **CNN** kayak **EfficientNet**, kita wajib memastikan semua gambar punya **ukuran yang sama** (**resize**).\n",
    "\n",
    "Selain itu, kita perlu melakukan **augmentasi** gambar. Tujuannya: bikin model kita jadi **lebih *robust*** dan nggak gampang *overfitting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0636216-9ed7-44b0-ae37-867875c12c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Library jangan lupa ya\n",
    "# Download kalo belum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afcef1a1-b4f8-49ad-8a8a-0b96284ed105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Generator berhasil dibuat.\n"
     ]
    }
   ],
   "source": [
    "# Tentukan ukuran gambar yang diinginkan (standar untuk EfficientNet)\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# URL gambar di dataset kamu adalah URL web, jadi kita perlu \n",
    "# membuat generator yang bisa mengambil data dari URL.\n",
    "# Untuk Google Colab/Jupyter Notebook, cara paling efisien \n",
    "# adalah dengan membuat generator yang mengunduh dan memuat gambar.\n",
    "\n",
    "# Karena mengunduh 100k gambar secara real-time saat training SANGAT lambat,\n",
    "# dalam konteks penelitian, kamu harus MENGUNDUH SEMUA GAMBAR terlebih dahulu \n",
    "# ke folder lokal (misal: 'dataset/images/').\n",
    "\n",
    "# ASUMSI: Gambar sudah diunduh dan disimpan di folder 'dataset/images'\n",
    "# Nama file gambar harus sesuai dengan indeks/ID di CSV.\n",
    "\n",
    "# --- Split Data (Train/Test) ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Kita gunakan index saja untuk split, bukan data mentah\n",
    "train_df, test_df, y_train, y_test = train_test_split(\n",
    "    df, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Image Data Generator dengan Augmentasi ---\n",
    "# Augmentasi hanya untuk data training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,              # Normalisasi\n",
    "    rotation_range=20,           # Augmentasi rotasi\n",
    "    width_shift_range=0.2,       # Augmentasi pergeseran\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,        # Augmentasi flip\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data testing/validasi hanya perlu normalisasi\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"Image Data Generator berhasil dibuat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a45ab4-f9c8-41ff-b49a-a157e83875da",
   "metadata": {},
   "source": [
    "## 3. Tahap Modeling (EfficientNet + Multi-label Head)\n",
    "\n",
    "Di tahap ini, kita akan merancang arsitektur model utama. Kita akan menggunakan **EfficientNet** sebagai *backbone* (untuk ekstraksi fitur gambar) dan menyambungkannya dengan **Multi-label Head** (untuk memprediksi banyak bahan sekaligus). Kita juga akan menyiapkan konfigurasi *training*-nya.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5624cc9e-1f5b-4740-800a-af06fa44f74e",
   "metadata": {},
   "source": [
    "### A. Definisi Model\n",
    "\n",
    "* **[BANTU LANJUTIN YAA CAPE NULISNYA]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8b640ef-488c-402e-af2d-bf14495a5abd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Pastikan variabel ini sudah didefinisikan di cell sebelumnya\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# IMG_SIZE = 224 # Contoh, sesuaikan dengan yang kamu pakai\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# NUM_CLASSES = len(mlb.classes_)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 1. Definisikan Input Layer secara eksplisit untuk mencegah Shape Mismatch\u001b[39;00m\n\u001b[1;32m     15\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m---> 17\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mEfficientNetB0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Load bobot ImageNet\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# JANGAN sertakan top layer bawaan\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Gunakan input layer yang sudah didefinisikan\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Freeze lapisan base model agar tidak dilatih ulang\u001b[39;00m\n\u001b[1;32m     24\u001b[0m base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \n",
      "File \u001b[0;32m~/miniconda3/envs/penelitian/lib/python3.10/site-packages/keras/src/applications/efficientnet.py:571\u001b[0m, in \u001b[0;36mEfficientNetB0\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[1;32m    556\u001b[0m     [\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.applications.efficientnet.EfficientNetB0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnetb0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    570\u001b[0m ):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEfficientNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/penelitian/lib/python3.10/site-packages/keras/src/applications/efficientnet.py:434\u001b[0m, in \u001b[0;36mEfficientNet\u001b[0;34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, weights_name)\u001b[0m\n\u001b[1;32m    427\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;241m+\u001b[39m file_suffix\n\u001b[1;32m    428\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[1;32m    429\u001b[0m         file_name,\n\u001b[1;32m    430\u001b[0m         BASE_WEIGHTS_PATH \u001b[38;5;241m+\u001b[39m file_name,\n\u001b[1;32m    431\u001b[0m         cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m         file_hash\u001b[38;5;241m=\u001b[39mfile_hash,\n\u001b[1;32m    433\u001b[0m     )\n\u001b[0;32m--> 434\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights)\n",
      "File \u001b[0;32m~/miniconda3/envs/penelitian/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/penelitian/lib/python3.10/site-packages/keras/src/legacy/saving/legacy_h5_format.py:447\u001b[0m, in \u001b[0;36m_set_weights\u001b[0;34m(instance, symbolic_weights, weight_values, name, skip_mismatch)\u001b[0m\n\u001b[1;32m    437\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    438\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping loading weights for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to mismatch in shape for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    445\u001b[0m             )\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor weight \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbolic_weights[i]\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight expects shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived saved weight \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         )\n\u001b[1;32m    454\u001b[0m     symbolic_weights[i]\u001b[38;5;241m.\u001b[39massign(weight_value)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(instance, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinalize_state\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m symbolic_weights:\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall\n",
    "from tensorflow.keras.applications import EfficientNetB0 \n",
    "\n",
    "# Pastikan variabel ini sudah didefinisikan di cell sebelumnya\n",
    "# IMG_SIZE = 224 # Contoh, sesuaikan dengan yang kamu pakai\n",
    "# NUM_CLASSES = len(mlb.classes_)\n",
    "\n",
    "# --- Load Pre-trained EfficientNet Backbone ---\n",
    "\n",
    "# 1. Definisikan Input Layer secara eksplisit untuk mencegah Shape Mismatch\n",
    "input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "base_model = EfficientNetB0(\n",
    "    weights='imagenet',         # Load bobot ImageNet\n",
    "    include_top=False,          # JANGAN sertakan top layer bawaan\n",
    "    input_tensor=input_tensor,  # Gunakan input layer yang sudah didefinisikan\n",
    ")\n",
    "\n",
    "# Freeze lapisan base model agar tidak dilatih ulang\n",
    "base_model.trainable = False \n",
    "\n",
    "# --- Tambahkan Classification Head Multi-Label ---\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) # Lapisan pooling\n",
    "x = Dense(512, activation='relu')(x) \n",
    "# Lapisan Output: Jumlah neuron = Jumlah kelas unik (bahan)\n",
    "predictions = Dense(NUM_CLASSES, activation='sigmoid')(x) \n",
    "\n",
    "# Definisikan Model dengan Input dan Output yang sudah disiapkan\n",
    "model = Model(inputs=input_tensor, outputs=predictions)\n",
    "\n",
    "# --- Compile Model ---\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    # LOSS WAJIB: BinaryCrossentropy untuk Multi-Label Classification\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\n",
    "        BinaryAccuracy(name='accuracy'),\n",
    "        # tf.keras.metrics sudah di-import sebagai Precision/Recall\n",
    "        Precision(name='precision'), \n",
    "        Recall(name='recall')\n",
    "        # F1 Score: Di Tensorflow 2.13+, sudah ada F1Score() bawaan. \n",
    "        # Kalau versimu lebih lama, F1 harus dihitung dari Precision/Recall\n",
    "        # F1Score(name='f1_score') \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n--- Arsitektur Model ---\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97d328-fedd-46e0-bd00-4cfc9d1744ef",
   "metadata": {},
   "source": [
    "### B. Pelatihan Model (Training)\n",
    "\n",
    "Ini adalah tahap *training* model, Kita akan menjalankan proses *fitting* model menggunakan *generator* data yang sudah kita definisikan sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8deedaae-d9ac-47df-8406-a80982e07cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selanjutnya: Buat generator gambar yang bisa memuat data dari image_url ke file lokal, lalu jalankan model.fit().\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSelanjutnya: Buat generator gambar yang bisa memuat data dari image_url ke file lokal, lalu jalankan model.fit().\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
